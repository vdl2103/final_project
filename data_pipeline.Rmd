---
title: "data_pipeline"
author: "Brennan Baker"
date: "November 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(pitchRx)
```


# Gathering pitch data!

Pitch data is scraped from the MLB website using tools in the pitchRx package. Data is scraped into an SQlite3 database that you should store on your computer so that you do not have to scrape it at a later time. You bring this data into an r session by creating SQlite3 database representations (called "pitch" and "atbat" below). Finally, we load in weather data and an index of the team names and their corresponding abbreviations.

```{r import all data}
# first argument is the path to the SQlite database. 
# if TRUE, will create a new SQlite3 database at path if path does not exist. Will connect to the existing database if path does exist.

my_db <- src_sqlite("./data/GamedayDB.sqlite3", create = TRUE)

# Only run the code below if you have never scraped the data. This code collects and stores all PITCHf/x data from one date to the next, and saves it as GamedayDB.sqlite3.
####### scrape(start = "2016-04-03", end = Sys.Date() - 1,
####### suffix = "inning/inning_all.xml", connect = my_db$con)


# Create pitch and atbat, which are representations of data in my_db. That is, pitch does not actually pull data from every pitch into memory, but is a portrayal of the relevant data sitting in my_db.
pitch = tbl(my_db$con, "pitch")
atbat = tbl(my_db$con, "atbat")


#Import team names data
team_names = read_csv("./data/team_abbrv.csv")

#Import weather data 
weather_db = read_csv("./data/weather.csv")

```

Below we bring the pitch data into r from the SQlite3 database using the representations created above. Then we tidy the pitch data and combine it with the weather data. 

```{r tidy pitch data, message = FALSE}
# First line collects data into an r dataframe from the pitch and atbat representations established above
pitch_tidy_db = collect(inner_join(pitch, atbat, by = c("num", "url"))) %>% 
  # Extract home and away team information from url link
  separate(gameday_link.x, into = c("remove", "away_home"), sep = ".............._") %>%
  separate(away_home, into = c("away", "home"), sep = "mlb_") %>% 
  # Tidy date
  mutate(date = ymd(date)) %>% 
  # Joining pitch with atbat created redundant columns coded .x or .y. Remove redundant cols ending with .y. Remove spanish columns ending with _es
  select(-ends_with(".y"), -ends_with("_es")) %>% 
  # Remove .x from the end of columns
  rename_at(.vars = vars(ends_with(".x")),
          .funs = funs(sub("[.]x$", "", .))) %>% 
  # Add full team names
  left_join(team_names) %>% 
  # Add weather data
  left_join(weather_db) %>% 
  # Remove stadiums with a roof
  filter(!home %in% c("aas", "nas", "tor", "ari", "sea", "hou", "tba", "mia", "1", "2")) %>%  
  separate(date, c("y", "m", "d")) 
```

Examining missing data

```{r missing data}
#Examining missing data
missing_data = pitch_tidy_db %>% 
  filter(is.na(start_speed)) %>% #we are missing pitch speed for 62,971 pitches 
  group_by(team_name) %>% 
  count() #see if the missing data are (roughly) evenly distributed among the teams 
```

