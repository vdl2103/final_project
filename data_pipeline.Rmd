---
title: "data_pipeline"
author: "Brennan Baker"
date: "November 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(pitchRx)
```


# Gathering pitch data!

Once you scrape, it is stored in the db even if you quit r. When you re open r, run everything except for the scrape function and that will load the data into the actual r session.
```{r import all data}
# first argument is the path to the SQlite database. 
# if TRUE, will create a new SQlite3 database at path if path does not exist. Will connect to the existing database if path does exist.

my_db <- src_sqlite("./data/GamedayDB.sqlite3", create = TRUE)

# Do not need to run this, as I already put this data into the GamedayDB.sqlite3 in google drive. Collect and store all PITCHf/x data from one date to the next. 
# scrape(start = "2016-04-03", end = Sys.Date() - 1,
# suffix = "inning/inning_all.xml", connect = my_db$con)

#tbl creates a reference to the SQL database
# First, create pitch and atbat, which are representations of data in my_db. That is, pitch does not actually pull data from every pitch into memory, but is a portrayal of the relevant data sitting in my_db.
pitch = tbl(my_db$con, "pitch")
atbat = tbl(my_db$con, "atbat")


#Import team names data
team_names = read_csv("./data/team_abbrv.csv")

#Import weather data 
weather_db = read_csv("./data/weather.csv")

```

Tidy the pitching data. 
```{r, message = FALSE, cache = TRUE}
# First line collects data into an r dataframe from the pitch and atbat representations established above
pitch_tidy_db = collect(inner_join(pitch, atbat, by = c("num", "url"))) %>% 
  # Extract home and away team information from url link
  separate(gameday_link.x, into = c("remove", "away_home"), sep = ".............._") %>%
  separate(away_home, into = c("away", "home"), sep = "mlb_") %>% 
  # Tidy date
  mutate(date = ymd(date)) %>% 
  # Joining pitch with atbat created redundant columns coded .x or .y. Remove redundant cols ending with .y. Remove spanish columns ending with _es
  select(-ends_with(".y"), -ends_with("_es")) %>% 
  # Remove .x from the end of columns
  rename_at(.vars = vars(ends_with(".x")),
          .funs = funs(sub("[.]x$", "", .))) %>% 
  # Add full team names
  left_join(team_names) %>% 
  # Add weather data
  left_join(weather_db) %>% 
  # Remove stadiums with a roof
  filter(!home %in% c("aas", "nas", "tor", "ari", "sea", "hou", "tba", "mia", "1", "2")) %>%  
  separate(date, c("y", "m", "d")) 
```

```{r}
pitch_tidy_db = pitch_tidy_db %>% 
  rename_at(.vars = vars(ends_with(".x")),
          .funs = funs(sub("[.]x$", "", .)))
```

```{r, message=FALSE}


#Join databases and remove: 1) teams with roofs, 2) spring training games, 3) AS games 
complete_db = left_join(pitch_tidy_db, weather_db) %>% 
  filter(!home %in% c("aas", "nas", "tor", "ari", "sea", "hou", "tba", "mia", "1", "2")) %>%  
  separate(date, c("y", "m", "d")) 
```

```{r}
#Examining missing data
missing_data = complete_db %>% 
  filter(is.na(start_speed)) %>% #we are missing pitch speed for 62,971 pitches 
  group_by(team_name) %>% 
  count() #see if the missing data are (roughly) evenly distributed among the teams 
```

```{r}
# Below runs a hierarchical linear model / nested model with pitcher_name set as the grouping factor.
# It takes a few minutes to run.
library(lme4)
# Without the below package, lme4 will not give you p-values.
library(lmerTest)
lme_results <- lmer(start_speed ~ heat_index + (1|pitcher_name), data=complete_db, REML=F)

# Summary of results.
summary(lme_results)
```

```{r}
complete_db %>%
  filter(pitch_type == "FF") %>% 
  ggplot(aes(x = tmax, y = start_speed)) +
  geom_point()
```

